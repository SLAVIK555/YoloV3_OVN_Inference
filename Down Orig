slava@slava-Inspiron-3583:/opt/intel/openvino_2021/deployment_tools/open_model_zoo/tools/downloader$ sudo python3 downloader.py --name yolo-v3-tf
[sudo] пароль для slava: 
################|| Downloading yolo-v3-tf ||################

========== Downloading /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.pb
... 100%, 242313 KB, 3703 KB/s, 65 seconds passed

========== Downloading /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.json
... 100%, 0 KB, 1786 KB/s, 0 seconds passed



python3 mo.p --input_model "/home/slava/Source/YoloV5_OVN_Inference/NewUbuntuConv/ColabSModel/best.onnx" --output_dir "/home/slava/Source/YoloV5_OVN_Inference/NewUbuntuConv/ColabSModel" --input_shape [1,3,320,320] --input images --scale 255 --data_type FP16 --output Conv_198,Conv_233,Conv_268 --model_name best --progress



slava@slava-Inspiron-3583:/opt/intel/openvino_2021/deployment_tools/model_optimizer$ python3 mo.py --input_model "/opt/intel/openvino_2021/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.pb" --output_dir "/home/slava/Source/YoloV3_OVN_Inference/mo_converted" --model_name yolo-v3-tf --input_shape [1,416,416,3] --progress
Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/opt/intel/openvino_2021/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.pb
	- Path for generated IR: 	/home/slava/Source/YoloV3_OVN_Inference/mo_converted
	- IR output name: 	yolo-v3-tf
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,416,416,3]
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- Enable grouped convolutions fusing: 	True
	- Move mean values to preprocess section: 	None
	- Reverse input channels: 	False
TensorFlow specific parameters:
	- Input model in text protobuf format: 	False
	- Path to model dump for TensorBoard: 	None
	- List of shared libraries with TensorFlow custom layers implementation: 	None
	- Update the configuration file with input/output node names: 	None
	- Use configuration file used to generate the model with Object Detection API: 	None
	- Use the config file: 	None
	- Inference Engine found in: 	/opt/intel/openvino_2021/python/python3.6/openvino
Inference Engine version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
Model Optimizer version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
2022-02-10 11:01:51.440259: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/openvino_2021/data_processing/dl_streamer/lib:/opt/intel/openvino_2021/data_processing/gstreamer/lib:/opt/intel/openvino_2021/opencv/lib:/opt/intel/openvino_2021/deployment_tools/ngraph/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/external/tbb/lib::/opt/intel/openvino_2021/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/external/omp/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/lib/intel64
2022-02-10 11:01:51.440297: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:22: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Progress: [....................] 100.00% done[ SUCCESS ] Generated IR version 10 model.
[ SUCCESS ] XML file: /home/slava/Source/YoloV3_OVN_Inference/mo_converted/yolo-v3-tf.xml
[ SUCCESS ] BIN file: /home/slava/Source/YoloV3_OVN_Inference/mo_converted/yolo-v3-tf.bin
[ SUCCESS ] Total execution time: 30.29 seconds. 
[ SUCCESS ] Memory consumed: 1797 MB. 
slava@slava-Inspiron-3583:/opt/intel/openvino_2021/deployment_tools/model_optimizer$ 



























slava@slava-Inspiron-3583:/opt/intel/openvino_2021/deployment_tools/open_model_zoo/tools/downloader$ sudo python3 converter.py --name yolo-v3-tf --mo /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py
========== Converting yolo-v3-tf to IR (FP16)
Conversion command: /usr/bin/python3 -- /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py --framework=tf --data_type=FP16 --output_dir=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/FP16 --model_name=yolo-v3-tf '--input_shape=[1,416,416,3]' --input=input_1 '--scale_values=input_1[255]' --reverse_input_channels --transformations_config=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.json --input_model=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.pb

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.pb
	- Path for generated IR: 	/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/FP16
	- IR output name: 	yolo-v3-tf
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	input_1
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,416,416,3]
	- Mean values: 	Not specified
	- Scale values: 	input_1[255]
	- Scale factor: 	Not specified
	- Precision of IR: 	FP16
	- Enable fusing: 	True
	- Enable grouped convolutions fusing: 	True
	- Move mean values to preprocess section: 	None
	- Reverse input channels: 	True
TensorFlow specific parameters:
	- Input model in text protobuf format: 	False
	- Path to model dump for TensorBoard: 	None
	- List of shared libraries with TensorFlow custom layers implementation: 	None
	- Update the configuration file with input/output node names: 	None
	- Use configuration file used to generate the model with Object Detection API: 	None
	- Use the config file: 	None
	- Inference Engine found in: 	/opt/intel/openvino_2021.4.752/python/python3.6/openvino
Inference Engine version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
Model Optimizer version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
2022-02-11 22:40:59.672799: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/intel/openvino_2021.4.752/deployment_tools/model_optimizer/mo/utils/../../../inference_engine/lib/intel64:/opt/intel/openvino_2021.4.752/deployment_tools/model_optimizer/mo/utils/../../../inference_engine/external/tbb/lib:/opt/intel/openvino_2021.4.752/deployment_tools/model_optimizer/mo/utils/../../../ngraph/lib
2022-02-11 22:40:59.672901: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:22: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
[ SUCCESS ] Generated IR version 10 model.
[ SUCCESS ] XML file: /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/FP16/yolo-v3-tf.xml
[ SUCCESS ] BIN file: /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/FP16/yolo-v3-tf.bin
[ SUCCESS ] Total execution time: 31.49 seconds. 
[ SUCCESS ] Memory consumed: 1770 MB. 

========== Converting yolo-v3-tf to IR (FP32)
Conversion command: /usr/bin/python3 -- /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py --framework=tf --data_type=FP32 --output_dir=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/FP32 --model_name=yolo-v3-tf '--input_shape=[1,416,416,3]' --input=input_1 '--scale_values=input_1[255]' --reverse_input_channels --transformations_config=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.json --input_model=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.pb

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/yolo-v3.pb
	- Path for generated IR: 	/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/FP32
	- IR output name: 	yolo-v3-tf
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	input_1
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,416,416,3]
	- Mean values: 	Not specified
	- Scale values: 	input_1[255]
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- Enable grouped convolutions fusing: 	True
	- Move mean values to preprocess section: 	None
	- Reverse input channels: 	True
TensorFlow specific parameters:
	- Input model in text protobuf format: 	False
	- Path to model dump for TensorBoard: 	None
	- List of shared libraries with TensorFlow custom layers implementation: 	None
	- Update the configuration file with input/output node names: 	None
	- Use configuration file used to generate the model with Object Detection API: 	None
	- Use the config file: 	None
	- Inference Engine found in: 	/opt/intel/openvino_2021.4.752/python/python3.6/openvino
Inference Engine version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
Model Optimizer version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
2022-02-11 22:41:31.832354: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/intel/openvino_2021.4.752/deployment_tools/model_optimizer/mo/utils/../../../inference_engine/lib/intel64:/opt/intel/openvino_2021.4.752/deployment_tools/model_optimizer/mo/utils/../../../inference_engine/external/tbb/lib:/opt/intel/openvino_2021.4.752/deployment_tools/model_optimizer/mo/utils/../../../ngraph/lib
2022-02-11 22:41:31.832392: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:22: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
[ SUCCESS ] Generated IR version 10 model.
[ SUCCESS ] XML file: /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/FP32/yolo-v3-tf.xml
[ SUCCESS ] BIN file: /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tf/FP32/yolo-v3-tf.bin
[ SUCCESS ] Total execution time: 28.45 seconds. 
[ SUCCESS ] Memory consumed: 1797 MB. 

slava@slava-Inspiron-3583:/opt/intel/openvino_2021/deployment_tools/open_model_zoo/tools/downloader$ 













sudo python3 converter.py --name yolo-v3-tiny-tf --mo /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py
========== Converting yolo-v3-tiny-tf to IR (FP16)
Conversion command: /usr/bin/python3 -- /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py --framework=tf --data_type=FP16 --output_dir=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/FP16 --model_name=yolo-v3-tiny-tf '--input_shape=[1,416,416,3]' --input=image_input '--scale_values=image_input[255]' --reverse_input_channels --transformations_config=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/yolo-v3-tiny-tf/yolo-v3-tiny-tf.json --input_model=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/yolo-v3-tiny-tf/yolo-v3-tiny-tf.pb

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/yolo-v3-tiny-tf/yolo-v3-tiny-tf.pb
	- Path for generated IR: 	/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/FP16
	- IR output name: 	yolo-v3-tiny-tf
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	image_input
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,416,416,3]
	- Mean values: 	Not specified
	- Scale values: 	image_input[255]
	- Scale factor: 	Not specified
	- Precision of IR: 	FP16
	- Enable fusing: 	True
	- Enable grouped convolutions fusing: 	True
	- Move mean values to preprocess section: 	None
	- Reverse input channels: 	True
TensorFlow specific parameters:
	- Input model in text protobuf format: 	False
	- Path to model dump for TensorBoard: 	None
	- List of shared libraries with TensorFlow custom layers implementation: 	None
	- Update the configuration file with input/output node names: 	None
	- Use configuration file used to generate the model with Object Detection API: 	None
	- Use the config file: 	None
	- Inference Engine found in: 	/opt/intel/openvino_2021.4.752/python/python3.6/openvino
Inference Engine version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
Model Optimizer version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
[ SUCCESS ] Generated IR version 10 model.
[ SUCCESS ] XML file: /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/FP16/yolo-v3-tiny-tf.xml
[ SUCCESS ] BIN file: /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/FP16/yolo-v3-tiny-tf.bin
[ SUCCESS ] Total execution time: 8.03 seconds. 
[ SUCCESS ] Memory consumed: 488 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*

========== Converting yolo-v3-tiny-tf to IR (FP32)
Conversion command: /usr/bin/python3 -- /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py --framework=tf --data_type=FP32 --output_dir=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/FP32 --model_name=yolo-v3-tiny-tf '--input_shape=[1,416,416,3]' --input=image_input '--scale_values=image_input[255]' --reverse_input_channels --transformations_config=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/yolo-v3-tiny-tf/yolo-v3-tiny-tf.json --input_model=/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/yolo-v3-tiny-tf/yolo-v3-tiny-tf.pb

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/yolo-v3-tiny-tf/yolo-v3-tiny-tf.pb
	- Path for generated IR: 	/opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/FP32
	- IR output name: 	yolo-v3-tiny-tf
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	image_input
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,416,416,3]
	- Mean values: 	Not specified
	- Scale values: 	image_input[255]
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- Enable grouped convolutions fusing: 	True
	- Move mean values to preprocess section: 	None
	- Reverse input channels: 	True
TensorFlow specific parameters:
	- Input model in text protobuf format: 	False
	- Path to model dump for TensorBoard: 	None
	- List of shared libraries with TensorFlow custom layers implementation: 	None
	- Update the configuration file with input/output node names: 	None
	- Use configuration file used to generate the model with Object Detection API: 	None
	- Use the config file: 	None
	- Inference Engine found in: 	/opt/intel/openvino_2021.4.752/python/python3.6/openvino
Inference Engine version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
Model Optimizer version: 	2021.4.2-3974-e2a469a3450-releases/2021/4
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
[ SUCCESS ] Generated IR version 10 model.
[ SUCCESS ] XML file: /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/FP32/yolo-v3-tiny-tf.xml
[ SUCCESS ] BIN file: /opt/intel/openvino_2021.4.752/deployment_tools/open_model_zoo/tools/downloader/public/yolo-v3-tiny-tf/FP32/yolo-v3-tiny-tf.bin
[ SUCCESS ] Total execution time: 6.20 seconds. 
[ SUCCESS ] Memory consumed: 492 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*


